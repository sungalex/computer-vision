{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda layer와 Concatenate layer를 사용하여 y = x + 2x^2 + 3x^3 + 1 관계를 fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = np.random.rand(1000,1) * 10 - 5\n",
    "y_train = 1 * x_train + 2 * x_train**2 + 3 * x_train**3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 [(None, 1), (None, 1 0           x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 3)            0           lambda[0][0]                     \n",
      "                                                                 lambda[0][1]                     \n",
      "                                                                 lambda[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            4           concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = layers.Input(shape=(1,), name='x')\n",
    "\n",
    "mul1, mul2, mul3 = layers.Lambda(lambda x: [x, x**2, x**3], name='lambda')(x)\n",
    "concat = layers.Concatenate(name='concat')([mul1, mul2, mul3])\n",
    "\n",
    "y = layers.Dense(1, name='y')(concat)\n",
    "\n",
    "model = models.Model(inputs=x, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 31486.7355 - val_loss: 33457.5633\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 30280.5147 - val_loss: 32201.4230\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 29085.9051 - val_loss: 30998.3500\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 27953.0183 - val_loss: 29774.5778\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 26846.3021 - val_loss: 28661.9362\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 25783.4027 - val_loss: 27571.0130\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 24752.9613 - val_loss: 26465.1635\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 23745.0452 - val_loss: 25407.5896\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 22767.7579 - val_loss: 24381.6466\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 21820.6749 - val_loss: 23385.7628\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 20905.0830 - val_loss: 22438.7728\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 20015.0460 - val_loss: 21511.3338\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 19157.1337 - val_loss: 20580.1948\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 18317.8409 - val_loss: 19719.2414\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 17517.9029 - val_loss: 18842.7163\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 16730.3456 - val_loss: 18052.9650\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 15977.9693 - val_loss: 17248.9192\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 15245.2487 - val_loss: 16472.2437\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 14536.6271 - val_loss: 15733.5110\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 13850.5076 - val_loss: 15006.3797\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 13189.7869 - val_loss: 14292.5982\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 12547.3587 - val_loss: 13611.4667\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 11927.9730 - val_loss: 12964.6604\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 11333.1632 - val_loss: 12318.8821\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 10752.8541 - val_loss: 11724.7511\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 10197.6908 - val_loss: 11129.6634\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 9663.0244 - val_loss: 10561.9374\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 9147.6022 - val_loss: 10010.5999\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 8650.0341 - val_loss: 9490.4057\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 8175.1109 - val_loss: 8970.9797\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 7714.5702 - val_loss: 8483.7950\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 7275.9299 - val_loss: 8007.1055\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 6852.3778 - val_loss: 7555.2740\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 6445.9422 - val_loss: 7126.0890\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 6058.6107 - val_loss: 6703.5591\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 5685.8938 - val_loss: 6306.7351\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5329.6032 - val_loss: 5917.9692\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 4988.0255 - val_loss: 5551.7808\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 4662.9334 - val_loss: 5201.6711\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 4353.2674 - val_loss: 4869.2680\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4058.5372 - val_loss: 4547.3700\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3777.6065 - val_loss: 4245.7391\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3511.7093 - val_loss: 3951.8892\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3257.6219 - val_loss: 3678.5366\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3018.7312 - val_loss: 3413.8219\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2791.6258 - val_loss: 3167.2442\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2577.0587 - val_loss: 2930.8024\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2374.2690 - val_loss: 2714.2460\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2185.2612 - val_loss: 2497.5101\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2004.8632 - val_loss: 2302.2123\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1837.2090 - val_loss: 2114.3155\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 1679.6822 - val_loss: 1938.9179\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1532.2388 - val_loss: 1779.3533\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1395.6720 - val_loss: 1620.5272\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1267.1967 - val_loss: 1479.4331\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 1148.7761 - val_loss: 1347.3200\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1038.5451 - val_loss: 1225.0678\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 938.0672 - val_loss: 1106.6467\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 843.9699 - val_loss: 999.4912\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 757.7913 - val_loss: 903.2576\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 679.1000 - val_loss: 813.3306\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 606.8804 - val_loss: 731.7460\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 541.1817 - val_loss: 655.4160\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 481.6589 - val_loss: 584.6751\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 427.6134 - val_loss: 521.0605\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 378.6609 - val_loss: 465.7703\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 334.9625 - val_loss: 412.4995\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 295.4111 - val_loss: 366.6150\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 260.5265 - val_loss: 323.3351\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 229.0734 - val_loss: 286.7303\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 201.5622 - val_loss: 252.5406\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 176.8024 - val_loss: 224.4076\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 155.4774 - val_loss: 196.6928\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 136.3959 - val_loss: 172.9533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 119.6951 - val_loss: 153.1032\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 105.2322 - val_loss: 134.6696\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 92.5372 - val_loss: 118.7994\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 81.6245 - val_loss: 104.4921\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 72.1107 - val_loss: 92.2036\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 63.8475 - val_loss: 81.9716\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 56.7915 - val_loss: 72.3469\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 50.6999 - val_loss: 64.0002\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 45.3674 - val_loss: 57.3950\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 40.8547 - val_loss: 51.4734\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 36.9327 - val_loss: 45.8864\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 33.5393 - val_loss: 41.3200\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 30.6134 - val_loss: 37.5966\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 28.0986 - val_loss: 33.9164\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 25.8848 - val_loss: 31.0052\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 23.9945 - val_loss: 28.3784\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 22.3691 - val_loss: 26.0457\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 20.9250 - val_loss: 24.1968\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 19.7230 - val_loss: 22.4038\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 18.6376 - val_loss: 20.9638\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 17.7274 - val_loss: 19.6218\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 16.9180 - val_loss: 18.5900\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 16.2430 - val_loss: 17.5431\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 15.6437 - val_loss: 16.7146\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 15.1336 - val_loss: 15.9854\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 14.6926 - val_loss: 15.3409\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 126us/step - loss: 14.3028 - val_loss: 14.8167\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 13.9750 - val_loss: 14.2830\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 13.6866 - val_loss: 13.8769\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 13.4340 - val_loss: 13.4979\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 13.2144 - val_loss: 13.1526\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 13.0185 - val_loss: 12.8572\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 12.8458 - val_loss: 12.6049\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 12.6820 - val_loss: 12.3954\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 12.5272 - val_loss: 12.1432\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 12.3863 - val_loss: 11.9551\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 12.2488 - val_loss: 11.7501\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 12.1196 - val_loss: 11.5767\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 11.9894 - val_loss: 11.4261\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 11.8662 - val_loss: 11.2686\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 11.7308 - val_loss: 11.1132\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 11.5989 - val_loss: 10.9535\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 11.4623 - val_loss: 10.8042\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 11.3322 - val_loss: 10.6594\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 11.1977 - val_loss: 10.5142\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 11.0558 - val_loss: 10.3759\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 10.9111 - val_loss: 10.2245\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 10.7665 - val_loss: 10.0750\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 10.6162 - val_loss: 9.9299\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 10.4593 - val_loss: 9.7785\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 10.3044 - val_loss: 9.6178\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 10.1462 - val_loss: 9.4624\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 9.9899 - val_loss: 9.3050\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 9.8215 - val_loss: 9.1442\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 9.6552 - val_loss: 8.9894\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 9.4853 - val_loss: 8.8377\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 9.3112 - val_loss: 8.6623\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 9.1395 - val_loss: 8.4770\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 8.9543 - val_loss: 8.3288\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 8.7777 - val_loss: 8.1515\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 8.5982 - val_loss: 7.9843\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 8.4113 - val_loss: 7.8028\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 8.2170 - val_loss: 7.6225\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 8.0346 - val_loss: 7.4387\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 7.8457 - val_loss: 7.2564\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 7.6507 - val_loss: 7.0813\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 7.4637 - val_loss: 6.8901\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 7.2672 - val_loss: 6.7220\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.0776 - val_loss: 6.5395\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 6.8860 - val_loss: 6.3493\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 6.6844 - val_loss: 6.1670\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 6.4885 - val_loss: 5.9715\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 6.2963 - val_loss: 5.7879\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 6.1095 - val_loss: 5.6241\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5.9076 - val_loss: 5.4397\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 5.7136 - val_loss: 5.2665\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 5.5244 - val_loss: 5.0687\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 138us/step - loss: 5.3307 - val_loss: 4.8987\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5.1429 - val_loss: 4.7149\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 4.9545 - val_loss: 4.5408\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 4.7665 - val_loss: 4.3619\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 4.5866 - val_loss: 4.2013\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 4.4062 - val_loss: 4.0258\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 4.2302 - val_loss: 3.8704\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 4.0453 - val_loss: 3.6946\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3.8769 - val_loss: 3.5348\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.7048 - val_loss: 3.3794\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 121us/step - loss: 3.5354 - val_loss: 3.2178\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 3.3960 - val_loss: 3.0727\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3.2265 - val_loss: 2.9251\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 3.0606 - val_loss: 2.7815\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 2.9088 - val_loss: 2.6324\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.7589 - val_loss: 2.4941\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.6159 - val_loss: 2.3646\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.4755 - val_loss: 2.2507\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3465 - val_loss: 2.1157\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 2.2031 - val_loss: 1.9888\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.0799 - val_loss: 1.8785\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.9562 - val_loss: 1.7574\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 1.8410 - val_loss: 1.6523\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.7170 - val_loss: 1.5601\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 1.6081 - val_loss: 1.4502\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.5052 - val_loss: 1.3476\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.4036 - val_loss: 1.2576\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 1.3087 - val_loss: 1.1688\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.2141 - val_loss: 1.0852\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 1.1238 - val_loss: 1.0127\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.0402 - val_loss: 0.9352\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.9604 - val_loss: 0.8571\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.8846 - val_loss: 0.7847\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.8120 - val_loss: 0.7179\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 0.7440 - val_loss: 0.6589\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.6814 - val_loss: 0.5981\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.6198 - val_loss: 0.5477\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.5641 - val_loss: 0.4941\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 0.5109 - val_loss: 0.4519\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.4619 - val_loss: 0.4085\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.4166 - val_loss: 0.3664\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.3730 - val_loss: 0.3269\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.3345 - val_loss: 0.2947\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.2983 - val_loss: 0.2593\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.2661 - val_loss: 0.2302\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.2327 - val_loss: 0.2059\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 0.2059 - val_loss: 0.1776\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.1799 - val_loss: 0.1557\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.1572 - val_loss: 0.1356\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mse')\n",
    "hist = model.fit(x_train, y_train, batch_size=10, epochs=200, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXyV9Zn//9eVlZ2whMWEsCOCImBEXFFURGsLztTWjlXa8VemVR/ftjoz0mnVTmt/bae7M9ZWqy1ap2oXK9+6IG61qCxhkVVI2MMaCEvCEkhyff+479QjZuOQc+6T5P18PM4j51znvs+5zs0h79z3517M3REREYlHWtQNiIhI66UQERGRuClEREQkbgoRERGJm0JERETiphAREZG4KUREEszMNpvZVVH3IZIIChEREYmbQkREROKmEBFJEjPLNrOfmtmO8PZTM8sOn+ttZn8xswNmVm5mfzOztPC5e8xsu5lVmNk6M7sy2k8i8oGMqBsQaUe+DkwExgIOPA98A7gXuBsoBXLDaScCbmZnAncC57v7DjMbBKQnt22RhmlNRCR5bga+5e573L0M+E/glvC5E0B/YKC7n3D3v3lwYrsaIBsYZWaZ7r7Z3TdE0r1IPRQiIslzBrAl5vGWsAbwA6AEeMXMNprZLAB3LwG+AnwT2GNmT5vZGYikCIWISPLsAAbGPC4Ia7h7hbvf7e5DgI8Dd9WNfbj7/7r7JeG8Dnw/uW2LNEwhIpI8vwO+YWa5ZtYbuA/4LYCZXW9mw8zMgEMEm7FqzOxMM5scDsAfA46Gz4mkBIWISPI8ABQBK4CVwNKwBjAceBWoBN4Ffu7ubxKMh3wP2AvsAvoA/5HUrkUaYboolYiIxEtrIiIiEjeFiIiIxC1hIWJmHcxskZm9Z2arzew/w/pvzGyTmS0Pb2PDupnZg2ZWYmYrzGx8zGvNMLPi8DYjpn6ema0M53kwHJQUEZEkSeQR61XAZHevNLNMYL6ZvRQ+92/u/oeTpr+WYHBxOHAB8DBwgZn1BO4HCgl2b1xiZnPcfX84zUxgAfAiMBV4CRERSYqEhUh4tG1l+DAzvDU2ij8NeCKcb4GZ5ZhZf+ByYJ67lwOY2Txgqpm9CXRz93fD+hPAdJoIkd69e/ugQYPi/VgiIu3SkiVL9rp77sn1hJ47y8zSgSXAMOAhd19oZl8CvmNm9wGvAbPcvQrIA7bFzF4a1hqrl9ZTr6+PmQRrLBQUFFBUVNQCn05EpP0wsy311RM6sO7uNe4+FsgHJpjZ2cDXgJHA+UBP4J66Hut7iTjq9fXxiLsXunthbu5HglREROKUlL2z3P0A8CYw1d13eqAK+DUwIZysFBgQM1s+wSkhGqvn11MXEZEkSeTeWblmlhPe7whcBbwfjnMQ7kk1HVgVzjIHuDXcS2sicNDddwJzgSlm1sPMegBTgLnhcxVmNjF8rVsJTq0tIiJJksgxkf7A7HBcJA141t3/Ymavm1kuweao5cAXw+lfBK4jOJPpEeDzAO5ebmbfBhaH032rbpAd+BLwG6AjwYC69swSEUmidnfak8LCQtfAuojIqTGzJe5eeHJdR6yLiEjcFCIiIhI3hUhzLXoUVv0x6i5ERFKKQqS5lj8FS2ZH3YWISEpRiDRX3nmwYxnU1kbdiYhIylCINNcZ46HqEOwriboTEZGUoRBprrzzgp/bl0Tbh4hIClGINFfv4ZDVVSEiIhJDIdJcaelwxliFiIhIDIXIqcg7D3athOqqqDsREUkJCpFTkXce1J6AXauanlZEpB1QiJwKDa6LiHyIQuRUdDsDuvRTiIiIhBQip8AhWBtRiIiIAAqRZrvlsYV8c85qyBsP+4rh6IGoWxIRiZxCpJnMjIWbyj8YF9mxLNqGRERSgEKkmcYNyGH97goqe48JCtqkJSKiEGmu8QN7UOuwosyh13DYvjTqlkREIqcQaaax+TkALNt2IBxcL4J2dmlhEZGTKUSaqXunTIbmdmbZ1v1BiFTuhkM7om5LRCRSCpFTMK6gB0u3HsDzxgcFjYuISDuXsBAxsw5mtsjM3jOz1Wb2n2F9sJktNLNiM3vGzLLCenb4uCR8flDMa30trK8zs2ti6lPDWomZzUrUZ6kzvqAH5YePszVrCKRlKkREpN1L5JpIFTDZ3c8FxgJTzWwi8H3gJ+4+HNgP3BZOfxuw392HAT8Jp8PMRgE3AaOBqcDPzSzdzNKBh4BrgVHAZ8JpE2ZcQTgusv0o9DtHISIi7V7CQsQDleHDzPDmwGTgD2F9NjA9vD8tfEz4/JVmZmH9aXevcvdNQAkwIbyVuPtGdz8OPB1OmzAj+nalc1Y6S7fuDw463LEcamsS+ZYiIiktoWMi4RrDcmAPMA/YABxw9+pwklIgL7yfB2wDCJ8/CPSKrZ80T0P1+vqYaWZFZlZUVlYW9+dJTzPOHZDDsq3hHlrHK2Dv+rhfT0SktUtoiLh7jbuPBfIJ1hzOqm+y8Kc18Nyp1uvr4xF3L3T3wtzc3KYbb8S4ghzW7jzEsb7h4Pq2Raf1eiIirVlS9s5y9wPAm8BEIMfMMsKn8oG6/WRLgQEA4fPdgfLY+knzNFRPqHEDelBd66w4mgudesPWBYl+SxGRlJXIvbNyzSwnvN8RuApYC7wBfDKcbAbwfHh/TviY8PnX3d3D+k3h3luDgeHAImAxMDzc2yuLYPB9TqI+T52/D65vOwAFE2Hru4l+SxGRlJXR9CRx6w/MDveiSgOedfe/mNka4GkzewBYBjwWTv8Y8KSZlRCsgdwE4O6rzexZYA1QDdzh7jUAZnYnMBdIBx5399UJ/DwA9OqSzcBenYJxkaEXwvt/gYpd0LVfot9aRCTlJCxE3H0FMK6e+kaC8ZGT68eAGxt4re8A36mn/iLw4mk3e4rGDcjhnQ378CsmBgMzW9+F0Tckuw0RkcjpiPU4jCvowZ6KKnZ0HAEZHTUuIiLtlkIkDuMLegCwbHsl5BdqXERE2i2FSBxG9u9KdkZaMC5ScCHsWglVFVG3JSKSdAqROGSmpzEmv3tw5HrBRPBaKF0cdVsiIkmnEInT+IIerN5+iKr+48HSNC4iIu2SQiRO4wpyOF5Ty+p9BCdj1LiIiLRDCpE4nTewJwBFm8uDcZHSIqg5EXFXIiLJpRCJU27XbAb37syiTeG4yIkjsGtF1G2JiCSVQuQ0nD+oB0VbyqnNvyAoaFxERNoZhchpOH9QTw4cOUHJsa7QY5DGRUSk3VGInIYJg4NxkUWbwnGRrQvA6z0bvYhIm6QQOQ0FPTvRp2s2izeXB+Mih8tg34ao2xIRSRqFyGkwM84f3JNFm8rxARODojZpiUg7ohA5TRMG9WTnwWOUpg+Ajj01uC4i7YpC5DSdPygYF1m8ZX84LvJOxB2JiCSPQuQ0ndmvK107ZATjIgMvgvKNcCjhV+kVEUkJCpHTlJ5mFA7sEeyhNeiSoLj57WibEhFJEoVICzh/cE82lB1mX5cRkN0dtsyPuiURkaRQiLSACXXjIlsPwsALYbNCRETaB4VICxiTn0PHzHTe3bAPBl4M+0qgYlfUbYmIJFzCQsTMBpjZG2a21sxWm9mXw/o3zWy7mS0Pb9fFzPM1Mysxs3Vmdk1MfWpYKzGzWTH1wWa20MyKzewZM8tK1OdpTFZGGucP7sk7G/bFjItobURE2r5ErolUA3e7+1nAROAOMxsVPvcTdx8b3l4ECJ+7CRgNTAV+bmbpZpYOPARcC4wCPhPzOt8PX2s4sB+4LYGfp1EXDe1F8Z5K9nQZAVldYYsG10Wk7UtYiLj7TndfGt6vANYCeY3MMg142t2r3H0TUAJMCG8l7r7R3Y8DTwPTzMyAycAfwvlnA9MT82madtHQXgC8u0njIiLSfiRlTMTMBgHjgIVh6U4zW2Fmj5tZj7CWB2yLma00rDVU7wUccPfqk+r1vf9MMysys6KysrIW+EQfNfqM7nTtkPHBuMje9VCxOyHvJSKSKhIeImbWBfgj8BV3PwQ8DAwFxgI7gR/VTVrP7B5H/aNF90fcvdDdC3Nzc0/xEzRPepoxcUivcFzk0qCoTVoi0sYlNETMLJMgQJ5y9z8BuPtud69x91rgUYLNVRCsSQyImT0f2NFIfS+QY2YZJ9Ujc9HQXmwtP0Jpx+GQ1UWbtESkzUvk3lkGPAasdfcfx9T7x0x2A7AqvD8HuMnMss1sMDAcWAQsBoaHe2JlEQy+z3F3B94APhnOPwN4PlGfpzkuGtobCMdFCiYqRESkzUvkmsjFwC3A5JN25/0vM1tpZiuAK4CvArj7auBZYA3wMnBHuMZSDdwJzCUYnH82nBbgHuAuMyshGCN5LIGfp0kj+nahV+esYFxk8GWwdx0c2hllSyIiCZXR9CTxcff51D9u8WIj83wH+E499Rfrm8/dN/LB5rDImRkXDg3GRfzSScGH3/RXOPemqFsTEUkIHbHewi4a2ptdh46xKWNIcH2RjW9G3ZKISMIoRFpY3fEi72zcD0MmwYY3dN11EWmzFCItbGCvTvTv3iEYFxlyBVTugrJ1UbclIpIQCpEWVjcu8u7GfdQOnhQUtUlLRNoohUgCXDS0N+WHj7Ouqif0GKwQEZE2SyGSABfWjYts2AdDLg+OF6k5EWlPIiKJoBBJgLycjgzq1Yl3N+yFoVfA8QrYviTqtkREWpxCJEEuHNqbBRvLOVFwCWDapCUibZJCJEEmjehNZVU1y8oMzhgb7OorItLGKEQS5KJhvUlPM95aXxbs6lu6GI4djLotEZEWpRBJkG4dMhk3IIe3istg2FXgNdqkJSJtjkIkgS4bkcvK7Qcp7zkWsrtB8byoWxIRaVEKkQS6bEQu7vC3jQeCXX1LXtMpUESkTVGIJNA5ed3J6ZTJX9eXwfApULEDdq9uekYRkVZCIZJA6WnGJcN687fivfiwK4NiiTZpiUjboRBJsEkjcimrqGJtZRfoew4Uvxp1SyIiLUYhkmCXjcgFCPbSGn4VbFsAxw5F3JWISMtQiCRY324dGNmva3C8yLCrobZau/qKSJuhEEmCSSNyWby5nMo+44NdfTUuIiJthEIkCa4Y2YcTNc78jQeDXX2LX9WuviLSJihEkuC8gT3o2iGD19/f/cGuvnvWRN2WiMhpS1iImNkAM3vDzNaa2Woz+3JY72lm88ysOPzZI6ybmT1oZiVmtsLMxse81oxw+mIzmxFTP8/MVobzPGhmlqjPczoy09OYNCKX198vo3ZouKuvjl4XkTYgkWsi1cDd7n4WMBG4w8xGAbOA19x9OPBa+BjgWmB4eJsJPAxB6AD3AxcAE4D764InnGZmzHxTE/h5TsuVZ/Vhb2UVKw91Cnf1VYiISOuXsBBx953uvjS8XwGsBfKAacDscLLZwPTw/jTgCQ8sAHLMrD9wDTDP3cvdfT8wD5gaPtfN3d91dweeiHmtlDNpRB/SDF5/f4929RWRNiMpYyJmNggYBywE+rr7TgiCBugTTpYHbIuZrTSsNVYvrade3/vPNLMiMysqKys73Y8Tl56dsxhf0CMIEe3qKyJtRMJDxMy6AH8EvuLujf3pXd94hsdR/2jR/RF3L3T3wtzc3KZaTpjJZ/Vh5faD7O4+BrK7Q/ErkfUiItISEhoiZpZJECBPufufwvLucFMU4c89Yb0UGBAzez6wo4l6fj31lDV5ZLDS9Ubxfhg2ORgXqa2NuCsRkfglcu8sAx4D1rr7j2OemgPU7WE1A3g+pn5ruJfWROBguLlrLjDFzHqEA+pTgLnhcxVmNjF8r1tjXislndm3K3k5HXnt/T0w/Bqo3AW73ou6LRGRuCVyTeRi4BZgspktD2/XAd8DrjazYuDq8DHAi8BGoAR4FLgdwN3LgW8Di8Pbt8IawJeAX4XzbABeSuDnOW1mxuSRfZhfvJdjgyYDBuu1SUtEWq+MRL2wu8+n/nELgCvrmd6BOxp4rceBx+upFwFnn0abSXfVqL48uWAL83fAVfmFsP5luPyeqNsSEYmLjlhPsguH9KJrhwxeWbMLRlwDO5bCoZ1RtyUiEheFSJJlZaQxeWQfXl27h+oRHwuKa/9vtE2JiMRJIRKBa0b3o/zwcYqO9IXcs2D1c1G3JCISF4VIBCaNyCUrI425q3fB6Omw9V2o2BV1WyIip0whEoHO2RlcOqw3r6zejY+aBjismRN1WyIip0whEpFrRvdj+4GjrD5xBuSOhDV/jrolEZFTphCJyJVnBSdkfGX1Lhh9A2x5R5u0RKTVaVaImNmXzaxbeDT5Y2a21MymJLq5tqxXl2zOH9STuat3w6jpaJOWiLRGzV0T+efw5IlTgFzg83xwpLnE6ZrR/Vi3u4KNlq9NWiLSKjU3ROqOPL8O+LW7v0fDR6NLM117Tj8AXlixU5u0RKRVam6ILDGzVwhCZK6ZdQV0+tnT1L97RwoH9uCFlTu1SUtEWqXmhshtBJexPd/djwCZBJu05DRdP6Y/7++qoIQ8bdISkVanuSFyIbDO3Q+Y2WeBbwAHE9dW+3HtOf0xgxdW7ArWRrRJS0RakeaGyMPAETM7F/h3YAvBNc3lNPXt1oHzB/XkhZU7gqPXcZ1LS0RajeaGSHV4qvZpwM/c/WdA18S11b5cP6Y/63dXst7DvbR0Li0RaSWaGyIVZvY1gotMvWBm6QTjItICpp7dL9yktVObtESkVWluiHwaqCI4XmQXkAf8IGFdtTN9unbggsE9eWHlzg/OpaVNWiLSCjQrRMLgeArobmbXA8fcXWMiLehjY86gZE8la2vqNmlpLy0RSX3NPe3Jp4BFwI3Ap4CFZvbJRDbW3lx3dj8y0oznl28PN2m9rU1aIpLymrs56+sEx4jMcPdbgQnAvYlrq/3p1SWbSSNyeX75DmpG3QA4rPpT1G2JiDSquSGS5u57Yh7va2peM3vczPaY2aqY2jfNbLuZLQ9v18U89zUzKzGzdWZ2TUx9algrMbNZMfXBZrbQzIrN7Bkzy2rmZ0lZ08flsevQMRZW9Ib+58KKZ6JuSUSkUc0NkZfNbK6Zfc7MPge8ALzYxDy/AabWU/+Ju48Nby8CmNko4CZgdDjPz80sPdwL7CHgWmAU8JlwWoDvh681HNhPcFR9q3bVWX3pkp3Bc8u2w5hPw87lULYu6rZERBrU3IH1fwMeAcYA5wKPuPs9TczzFlDezD6mAU+7e5W7bwJKCDaZTQBK3H2jux8HngammZkBk4E/hPPPBqY3871SVsesdKae3Y+XVu3i2JnTwdJgxbNRtyUi0qBmX5TK3f/o7ne5+1fd/XSOhrvTzFaEm7t6hLU8YFvMNKVhraF6L+CAu1efVK+Xmc00syIzKyorKzuN1hPvhnF5VFZV82qpwZArYOWzUKtzXYpIampqXKPCzA7Vc6sws0NxvN/DwFBgLLAT+FHdW9UzrcdRr5e7P+Luhe5emJube2odJ9nEIb3o160Df67bpHVgK2xbGHVbIiL1ajRE3L2ru3er59bV3bud6pu5+253r3H3WuBRgs1VEKxJDIiZNB/Y0Uh9L5BjZhkn1Vu99DRj2tgzeHNdGeUFV0NmJw2wi0jKSuo11s2sf8zDG4C6PbfmADeZWbaZDQaGExyXshgYHu6JlUUw+D4nPI/XG0DdsSozgOeT8RmS4YbxeVTXOn9efRBGXh+cS6u6Kuq2REQ+ImEhYma/A94FzjSzUjO7DfgvM1tpZiuAK4CvArj7auBZYA3wMnBHuMZSDdwJzAXWAs+G0wLcA9xlZiUEYySPJeqzJNvIft0Yk9+dZ4u24WM+BccOwPqXo25LROQjLPijvv0oLCz0oqKiqNto0pMLtnDvn1fxf2+/kHN+fzH0HQ2f/UPTM4qIJICZLXH3wpPrSd2cJc33iXPPIDsjjWeWbodxN0PJq3CwNOq2REQ+RCGSorp3zOTas/vx/PIdVJ3zT4DDsqeibktE5EMUIinsU4UDqDhWzcvbs2HI5bDsSaitibotEZG/U4iksIlDejGgZ0eeWbwNxt8KB7fBxjejbktE5O8UIiksLc248bwBvLNhH1v7TIaOPWCpLuMiIqlDIZLibizMJ83gd0t3w5ib4P0X4PC+qNsSEQEUIimvf/eOXHlWX55dvI3j594MtSfgvf+Nui0REUAh0ip8duJA9h0+zkt7ekL+BFjyG2hnx/eISGpSiLQClw7rzcBenXhqwVYo/DzsK4HN86NuS0REIdIapKUZ/zShgEWby1nf+yro0B2W/DrqtkREFCKtxY2FA8jKSOO3S/bA2JthzfNwaGfUbYlIO6cQaSV6ds7iY+f0509Lt3Nk7G3BQYeLH426LRFp5xQirchnJw6ksqqaP27OhJEfg6LH4fiRqNsSkXZMIdKKjC/IYUx+d349fxO1F9wOR/fDiqejbktE2jGFSCtiZtx2yWA27j3Mm8eGQv+xsOBhXYNdRCKjEGllrjunP327ZfPY25vhwjtg7/rgNPEiIhFQiLQymelp3HrhIN4u2cf7vSZD1/6w4KGo2xKRdkoh0grdfEEBHTLTePzd7TDhC8GZfXevbnI+EZGWphBphXI6ZfGP4/P58/Id7Bt5M2R0hAU/j7otEWmHFCKt1OcvHszx6lp+s+wgjP0MrPg9VJZF3ZaItDMKkVZqWJ8uXDO6L7Pf2UzluC9ATRUs+mXUbYlIO5OwEDGzx81sj5mtiqn1NLN5ZlYc/uwR1s3MHjSzEjNbYWbjY+aZEU5fbGYzYurnmdnKcJ4HzcwS9VlS1e2XD+PQsWqeKsmGsz4OCx+BYwejbktE2pFEron8Bph6Um0W8Jq7DwdeCx8DXAsMD28zgYchCB3gfuACYAJwf13whNPMjJnv5Pdq884dkMMlw3rzq/mbqLrwLqg6CIt/FXVbItKOJCxE3P0toPyk8jRgdnh/NjA9pv6EBxYAOWbWH7gGmOfu5e6+H5gHTA2f6+bu77q7A0/EvFa7cvsVQymrqOL3O3rBsKvh3Yfg+OGo2xKRdiLZYyJ93X0nQPizT1jPA7bFTFca1hqrl9ZTr5eZzTSzIjMrKitrW4PPFw7pxbiCHH751gaqL7kbjuwLLlolIpIEqTKwXt94hsdRr5e7P+Luhe5emJubG2eLqcnMuP3yYWwrP8qc8gEw6FJ457/hxLGoWxORdiDZIbI73BRF+HNPWC8FBsRMlw/saKKeX0+9XbpyZB/O6t+NB18rpuaSu6FiJyx7Muq2RKQdSHaIzAHq9rCaATwfU7813EtrInAw3Nw1F5hiZj3CAfUpwNzwuQozmxjulXVrzGu1O2lpxl1Xj2DzviP8sXwoDJgIf/sRnDgadWsi0sYlchff3wHvAmeaWamZ3QZ8D7jazIqBq8PHAC8CG4ES4FHgdgB3Lwe+DSwOb98KawBfAn4VzrMBeClRn6U1uOqsPpyb352fvV7CiUn/EayNFOkSuiKSWBbs3NR+FBYWelFRUdRtJMSb6/bwuV8v5oHpZ/PZdXfCnrXw5fcgq3PUrYlIK2dmS9y98OR6qgysSwuYNCKX8QU5/M/rJVRd9jU4XAaLHom6LRFpwxQibYiZcfeUM9l16BhPbe8fHDcy/6c6il1EEkYh0sZcNLQXFw/rxX+/XkzFxffAsQPBAYgiIgmgEGljzIz/uO4sDhw9wf+83wVGTQ+OGzm0M+rWRKQNUoi0QaPP6M4N4/L49dub2Xn+PVBzAt54IOq2RKQNUoi0Uf865UwM+P7CKrjgX2DZU7BrVZPziYicCoVIG3VGTkf+v0sH8+flO1g99AvQoTu88g1oZ7t0i0hiKUTasC9OGkrvLlncN28HtZf9O2x8A0pejbotEWlDFCJtWNcOmdwzdSRLtuznTxnXQs8h8PIsqK6KujURaSMUIm3cP47PZ3xBDt+du4HDV34X9pUEe2uJiLQAhUgbl5ZmfGva2ew/cpz/KsmHsz4Bb/0A9m+OujURaQMUIu3A2XnduWXiQJ5csIV14/4DLB1emtX0jCIiTVCItBN3TTmTnp2z+PdX9lEz6R5Y/xK8/0LUbYlIK6cQaSe6d8zk/o+P5r3SgzxefQ30GQUv/pvOqyUip0Uh0o5cP6Y/V4/qyw9f3cT2ST8Irjnyyr1RtyUirZhCpB0xMx6YfjZZGWl8dX46PvFOWDobNrwRdWsi0kopRNqZvt06cO/HRrFoUzm/63wz9BoGc/4PVFVE3ZqItEIKkXboxsJ8Lh3em2/P3UzppB/CwW0w776o2xKRVkgh0g6ZGT+88Vw6ZKbxpb9mUjPxDih6HN5/MerWRKSVUYi0U327deC7/zCGldsP8pPaT0O/MfD8HXBoR9StiUgrEkmImNlmM1tpZsvNrCis9TSzeWZWHP7sEdbNzB40sxIzW2Fm42NeZ0Y4fbGZzYjis7RmU8/ux2cmDOChv21j2YQfQ/UxeO5foLYm6tZEpJWIck3kCncf6+6F4eNZwGvuPhx4LXwMcC0wPLzNBB6GIHSA+4ELgAnA/XXBI8137/WjGNyrM198+SAVV/z/sOktePunUbclIq1EKm3OmgbMDu/PBqbH1J/wwAIgx8z6A9cA89y93N33A/OAqcluurXrlJXB//zTeA4ePcEXVp5J7agb4PUHYOObUbcmIq1AVCHiwCtmtsTMZoa1vu6+EyD82Ses5wHbYuYtDWsN1T/CzGaaWZGZFZWVlbXgx2gbRp3Rje9MP4cFm/bzk453Qu8R8PvPw4GtUbcmIikuqhC52N3HE2yqusPMLmtkWqun5o3UP1p0f8TdC929MDc399S7bQf+8bx8br6ggP9+ezdvjf8J1FbDM7fAiaNRtyYiKSySEHH3HeHPPcBzBGMau8PNVIQ/94STlwIDYmbPB3Y0Upc43ffxUZw7IIcvvnSILZN+DDuXw1++qkvqikiDkh4iZtbZzLrW3QemAKuAOUDdHlYzgOfD+3OAW8O9tCYCB8PNXXOBKWbWIxxQnxLWJE7ZGek8cst5dO+Yyafe7EHlxH+F934Hb/0w6tZEJEVFsSbSF5hvZu8Bi4AX3P1l4HvA1WZWDFwdPgZ4EdgIlACPArcDuHs58G1gcXj7VliT09C3Wwce/9z5VB6r5tPrJlE9+kZ44wF475moWxORFGTezjZVFBYWelFRUdRtpLw31osKrIMAAAzVSURBVO3htt8s5soRPfgl3yFt20K45TkYfGnUrYlIBMxsScwhGX+XSrv4Sgq54sw+fHv62cxbt59ZmffgPYfA0zfDjuVRtyYiKUQhIg26+YKBzLp2JM+uquB7vb6Dd+gGT94Au9dE3ZqIpAiFiDTqi5OGcucVw/jle8f5nwE/xjOy4YlpsLck6tZEJAUoRKRJd08ZwecvHsSPik7ws7wf4l4Ls6+HsnVRtyYiEVOISJPMjPuuH8W/TBrCT5cbP+j3gyBIHp8K25dG3Z6IREghIs1iZsyaOpK7rh7Bz9dkc1/PH1Kb1QVmfwI2/S3q9kQkIgoRaTYz4/9cOZx7rx/Fk+vT+ULGA1R36Q+//QdY9lTU7YlIBBQicspuu2QwD988nrf3ZPGJI1/nSL/z4fnb4aVZUFMddXsikkQKEYnLtef055mZF1JW04WLSu9k07AZsPBh+O0NcEQnDhBpLxQiErdzB+Tw5zsuZlCf7lyx6hqeG/gNfOtCeGQS7FwRdXsikgQKETkteTkdefZfLuSfLx7MV9eN4t+6fJfqE8fhV1fC2w9CbW3ULYpIAilE5LRlZaRx38dH8YvPjmfeoQFccvBbbO55Ccy7F574BBzY1vSLiEirpBCRFjP17P7M++plnD18CJdvu42Hun2Vmu1L4aEJwenkq6uiblFEWphCRFpUn24dePTWQn5441gerbyIyw9/lzWdJ8Dr34aHLoD1uuSLSFuiEJEWZ2Z88rx83rj7ciZNGM/1u2fypbR7OVAF/O+n4KlPwa5VUbcpIi1AISIJ06NzFg9MP4c5d17CoTMu4fzy/+SnaTM4vult+MXFOrW8SBugi1JJ0izYuI8fv7Ke9zdv5faOr/K5tJfoUFMBgyfBxNth+BRI0981IqmooYtSKUQkqdydhZvKeWz+Jhau3cQtGa9xW/ar9Kwuw3sOwcZ9Fs65EXIKom5VRGIoREIKkdSxee9hnlywhb8s3cL5x97mtqxXGcdaAGoLLiJt1CeCtZNeQyPuVEQUIiGFSOo5Xl3Lm+v28Kel2ylev4qptfP5h8x3GEpp8HzOUDJHTsWGXw35hZDdNeKORdofhUhIIZLajh6v4a3iMuat2c2W4lWMPryAyWnLmJi+liyqqSWNIzkjyBg4gQ6DL4R+Y6DXMMjsEHXrIm1amw0RM5sK/AxIB37l7t9rbHqFSOvh7mzZd4R3N+5jSfE2fPM7FBxdwzgrZmxaCd3sKAC1pHGoYx5VOcNIyz2T7N6D6JQ7kIweBdA9DzrkgFnEn0akdWuTIWJm6cB64GqgFFgMfMbd1zQ0j0KkdTtw5Dhrdh5izfYD7Nu8kvSytXSr3Ehe9RaG2Q4G2S6y7cOnoz9OFoczunEsoztVmTmcyM6hOrsndOhGWnYXLLMTZHfGsjqRlt2ZtKzOpGd3JiOzAxlZWWRmZpKekQXpGaSlZZCWkUlaeiaWkUlaegZp6eHjtHSFlbRZDYVIRhTNtKAJQIm7bwQws6eBaUCDISKtW06nLC4a2puLhvaGy4YBNwBQcewEW/Yd4Y3ySir37eRE+Vb8YCmZldvJPLqXzOP76VJ1kC5HK8jxHfSxSrpzmAxr+RNE1rrhgGM4QajU3XfArYE6Bnx43uBPvIaDyeN8rjGp9ZqNzdfwZC3ymh957qPzWSPPNb+fRuZr5I+SeD5jv39fRHaHTnH10pDWHiJ5QOzZ/UqBC06eyMxmAjMBCgq062hb1LVDJmfndefsvO4EX4uP/MH0dydqajlcVc2uqmoqjxyh+uhhaqoqqak6Qk1VJbXHD8PxI9ScqKKmupramuPBxbZqqzGvhppqrLYavIa02hNQW4N5NVZbE/wS8hrcHcKb41jwBMRGhjt1v7bq7n8QG+H8jf1aO2krQuwjo5Hn3Bt8VcNPftkGX/OkZhp5Kr6tHbHvd/JLfOi5Ruarp5mG36+ePusqjb9mU2/TyHvW81xT7+nU32tjr1mnv7X8cVitPUTqi9uPLEF3fwR4BILNWYluSlJbZnoaOZ2yyOmUBT06Ab2jbkmk1WrthweXAgNiHucDOyLqRUSk3WntIbIYGG5mg80sC7gJmBNxTyIi7Uar3pzl7tVmdicwl2AX38fdfXXEbYmItButOkQA3P1F4MWo+xARaY9a++YsERGJkEJERETiphAREZG4KURERCRurfrcWfEwszJgS5yz9wb2tmA7LUV9nbpU7U19nZpU7QtSt7d4+xro7rknF9tdiJwOMyuq7wRkUVNfpy5Ve1NfpyZV+4LU7a2l+9LmLBERiZtCRERE4qYQOTWPRN1AA9TXqUvV3tTXqUnVviB1e2vRvjQmIiIicdOaiIiIxE0hIiIicVOINIOZTTWzdWZWYmazIu5lgJm9YWZrzWy1mX05rH/TzLab2fLwdl0EvW02s5Xh+xeFtZ5mNs/MisOfPZLc05kxy2S5mR0ys69EtbzM7HEz22Nmq2Jq9S4jCzwYfu9WmNn4JPf1AzN7P3zv58wsJ6wPMrOjMcvuF0nuq8F/OzP7Wri81pnZNUnu65mYnjab2fKwnszl1dDvh8R9x9xdt0ZuBKeY3wAMAbKA94BREfbTHxgf3u8KrAdGAd8E/jXiZbUZ6H1S7b+AWeH9WcD3I/633AUMjGp5AZcB44FVTS0j4DrgJYIreE4EFia5rylARnj/+zF9DYqdLoLlVe+/Xfj/4D0gGxgc/r9NT1ZfJz3/I+C+CJZXQ78fEvYd05pI0yYAJe6+0d2PA08D06Jqxt13uvvS8H4FsJbgouKpahowO7w/G5geYS9XAhvcPd4zFpw2d38LKD+p3NAymgY84YEFQI6Z9U9WX+7+irtXhw8XEFw5NKkaWF4NmQY87e5V7r4JKCH4/5vUvszMgE8Bv0vEezemkd8PCfuOKUSalgdsi3lcSor80jazQcA4YGFYujNcJX082ZuNQg68YmZLzGxmWOvr7jsh+IIDfSLoq85NfPg/dtTLq05DyyiVvnv/TPAXa53BZrbMzP5qZpdG0E99/3apsrwuBXa7e3FMLenL66TfDwn7jilEmmb11CLfL9rMugB/BL7i7oeAh4GhwFhgJ8HqdLJd7O7jgWuBO8zssgh6qJcFl0/+BPD7sJQKy6spKfHdM7OvA9XAU2FpJ1Dg7uOAu4D/NbNuSWypoX+7lFhewGf48B8rSV9e9fx+aHDSemqntMwUIk0rBQbEPM4HdkTUCwBmlknwBXnK3f8E4O673b3G3WuBR0nQanxj3H1H+HMP8FzYw+661ePw555k9xW6Fljq7rvDHiNfXjEaWkaRf/fMbAZwPXCzhxvRw81F+8L7SwjGHkYkq6dG/u1SYXllAP8APFNXS/byqu/3Awn8jilEmrYYGG5mg8O/Zm8C5kTVTLi99TFgrbv/OKYeux3zBmDVyfMmuK/OZta17j7BoOwqgmU1I5xsBvB8MvuK8aG/DqNeXidpaBnNAW4N96CZCBys2ySRDGY2FbgH+IS7H4mp55pZenh/CDAc2JjEvhr6t5sD3GRm2WY2OOxrUbL6Cl0FvO/upXWFZC6vhn4/kMjvWDL2GGjtN4I9GNYT/AXx9Yh7uYRgdXMFsDy8XQc8CawM63OA/knuawjBnjHvAavrlhPQC3gNKA5/9oxgmXUC9gHdY2qRLC+CINsJnCD4K/C2hpYRwaaGh8Lv3UqgMMl9lRBsL6/7nv0inPYfw3/j94ClwMeT3FeD/3bA18PltQ64Npl9hfXfAF88adpkLq+Gfj8k7Dum056IiEjctDlLRETiphAREZG4KURERCRuChEREYmbQkREROKmEBFpJczscjP7S9R9iMRSiIiISNwUIiItzMw+a2aLwmtH/NLM0s2s0sx+ZGZLzew1M8sNpx1rZgvsg2t21F3nYZiZvWpm74XzDA1fvouZ/cGC63w8FR6hLBIZhYhICzKzs4BPE5yMcixQA9wMdCY4d9d44K/A/eEsTwD3uPsYgiOG6+pPAQ+5+7nARQRHR0NwVtavEFwjYghwccI/lEgjMqJuQKSNuRI4D1gcriR0JDjZXS0fnJTvt8CfzKw7kOPufw3rs4Hfh+cgy3P35wDc/RhA+HqLPDwvkwVXzhsEzE/8xxKpn0JEpGUZMNvdv/ahotm9J03X2PmGGttEVRVzvwb9H5aIaXOWSMt6DfikmfWBv1/beiDB/7VPhtP8EzDf3Q8C+2MuUnQL8FcPrv9QambTw9fINrNOSf0UIs2kv2JEWpC7rzGzbxBc4TGN4CyvdwCHgdFmtgQ4SDBuAsFpuX8RhsRG4PNh/Rbgl2b2rfA1bkzixxBpNp3FVyQJzKzS3btE3YdIS9PmLBERiZvWREREJG5aExERkbgpREREJG4KERERiZtCRERE4qYQERGRuP0/s1Wzoil1S/cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_weights:\n",
      " [array([[1.3327758],\n",
      "       [1.9967649],\n",
      "       [2.9816322]], dtype=float32), array([1.0248761], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "y_weights = model.get_layer('y').get_weights()\n",
    "print('y_weights:\\n', y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

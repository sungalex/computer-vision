{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Lambda layer 와 Concatenate layer 를 사용하여 y = x + 2x^2 + 3x^3 + 1 관계를 피팅"
=======
    "### lambda layer와 Concatenate layer를 사용하여 y = x + 2x^2 + 3x^3 + 1 관계를 fitting"
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
<<<<<<< HEAD
    },
=======
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = np.random.rand(1000,1) * 10 - 5\n",
    "y_train = 1 * x_train + 2 * x_train**2 + 3 * x_train**3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
<<<<<<< HEAD
      "h1_ABC (Lambda)                 [(None, 1), (None, 1 0           x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 3)            0           h1_ABC[0][0]                     \n",
      "                                                                 h1_ABC[0][1]                     \n",
      "                                                                 h1_ABC[0][2]                     \n",
=======
      "lambda (Lambda)                 [(None, 1), (None, 1 0           x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 3)            0           lambda[0][0]                     \n",
      "                                                                 lambda[0][1]                     \n",
      "                                                                 lambda[0][2]                     \n",
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            4           concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
<<<<<<< HEAD
      "__________________________________________________________________________________________________\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 12180.1112 - val_loss: 10145.1844\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 190us/step - loss: 11226.0414 - val_loss: 9339.8587\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 10346.0991 - val_loss: 8580.7747\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 9515.4907 - val_loss: 7870.6032\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 8733.8157 - val_loss: 7223.2765\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 8012.0358 - val_loss: 6582.8464\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 7328.1766 - val_loss: 6016.5156\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 6694.1067 - val_loss: 5469.9834\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 6097.8877 - val_loss: 4981.6104\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 5546.1136 - val_loss: 4516.7881\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 196us/step - loss: 5031.2121 - val_loss: 4078.4452\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 4554.7058 - val_loss: 3675.0118\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 4111.2520 - val_loss: 3319.1925\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 3705.8462 - val_loss: 2964.6458\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 3326.9028 - val_loss: 2655.9997\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2978.7460 - val_loss: 2371.8542\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2659.3726 - val_loss: 2107.0529\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2366.4332 - val_loss: 1864.1375\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 2098.2670 - val_loss: 1644.0871\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1854.1079 - val_loss: 1445.0312\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1632.1525 - val_loss: 1266.6682\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1432.4160 - val_loss: 1103.6149\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1251.1955 - val_loss: 961.8960\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 1089.3828 - val_loss: 833.0096\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 945.4174 - val_loss: 711.8935\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 815.5768 - val_loss: 612.3938\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 701.2323 - val_loss: 525.7406\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 600.8874 - val_loss: 446.7560\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 512.3769 - val_loss: 378.5509\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 435.4041 - val_loss: 319.6348\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 368.4713 - val_loss: 270.0051\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 311.1079 - val_loss: 225.8304\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 261.6673 - val_loss: 190.1460\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 219.8416 - val_loss: 158.6424\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 184.2166 - val_loss: 132.5249\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 154.2625 - val_loss: 110.5298\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 129.0870 - val_loss: 92.7556\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 198us/step - loss: 108.0112 - val_loss: 78.0088\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 90.4311 - val_loss: 66.0905\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 75.9319 - val_loss: 55.5347\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 63.7487 - val_loss: 47.0397\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 198us/step - loss: 53.6861 - val_loss: 40.0199\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 45.2869 - val_loss: 34.0702\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 38.2477 - val_loss: 29.1479\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 32.3727 - val_loss: 24.9107\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 27.4301 - val_loss: 21.3322\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 23.2644 - val_loss: 18.2402\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 19.7140 - val_loss: 15.6301\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 16.7039 - val_loss: 13.2963\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 14.1254 - val_loss: 11.3342\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 11.9399 - val_loss: 9.6340\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 10.0602 - val_loss: 8.1604\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 8.4695 - val_loss: 6.8984\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 7.1272 - val_loss: 5.8234\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 5.9989 - val_loss: 4.9308\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 5.0584 - val_loss: 4.1818\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 196us/step - loss: 4.2746 - val_loss: 3.5536\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.6392 - val_loss: 3.0621\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 3.1209 - val_loss: 2.6459\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.6995 - val_loss: 2.3262\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.3717 - val_loss: 2.0713\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 2.1102 - val_loss: 1.8736\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 182us/step - loss: 1.9059 - val_loss: 1.7193\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.7482 - val_loss: 1.6027\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 190us/step - loss: 1.6261 - val_loss: 1.5150\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.5311 - val_loss: 1.4444\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4563 - val_loss: 1.3899\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.3989 - val_loss: 1.3469\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.3504 - val_loss: 1.3111\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.3116 - val_loss: 1.2793\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.2765 - val_loss: 1.2501\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.2456 - val_loss: 1.2240\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.2162 - val_loss: 1.1960\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.1873 - val_loss: 1.1704\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.1592 - val_loss: 1.1426\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.1313 - val_loss: 1.1156\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.1028 - val_loss: 1.0878\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.0743 - val_loss: 1.0594\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.0452 - val_loss: 1.0297\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.0166 - val_loss: 0.9993\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.9854 - val_loss: 0.9695\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.9555 - val_loss: 0.9384\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.9251 - val_loss: 0.9070\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.8940 - val_loss: 0.8763\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.8630 - val_loss: 0.8432\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.8316 - val_loss: 0.8113\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.7991 - val_loss: 0.7792\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 174us/step - loss: 0.7663 - val_loss: 0.7484\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.7349 - val_loss: 0.7156\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.7024 - val_loss: 0.6826\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.6706 - val_loss: 0.6498\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.6389 - val_loss: 0.6180\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.6077 - val_loss: 0.5865\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.5764 - val_loss: 0.5554\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.5444 - val_loss: 0.5257\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.5150 - val_loss: 0.4959\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.4854 - val_loss: 0.4667\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.4546 - val_loss: 0.4351\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 171us/step - loss: 0.4265 - val_loss: 0.4069\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.3977 - val_loss: 0.3799\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.3707 - val_loss: 0.3532\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.3447 - val_loss: 0.3270\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.3178 - val_loss: 0.3008\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.2945 - val_loss: 0.2777\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.2703 - val_loss: 0.2542\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.2471 - val_loss: 0.2327\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.2253 - val_loss: 0.2116\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.2053 - val_loss: 0.1911\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.1859 - val_loss: 0.1726\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.1673 - val_loss: 0.1555\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.1499 - val_loss: 0.1391\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.1337 - val_loss: 0.1245\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1195 - val_loss: 0.1102\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1054 - val_loss: 0.0966\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0924 - val_loss: 0.0845\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.0812 - val_loss: 0.0737\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0703 - val_loss: 0.0638\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0606 - val_loss: 0.0559\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.0523 - val_loss: 0.0471\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0445 - val_loss: 0.0400\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0379 - val_loss: 0.0336\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0318 - val_loss: 0.0279\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0263 - val_loss: 0.0232\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0218 - val_loss: 0.0191\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0178 - val_loss: 0.0156\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 9.6120e-04 - val_loss: 7.7686e-04\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 6.7015e-04 - val_loss: 5.3414e-04\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - ETA: 0s - loss: 4.7975e-0 - 0s 177us/step - loss: 4.5957e-04 - val_loss: 3.6323e-04\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.0815e-04 - val_loss: 2.4522e-04\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.0695e-04 - val_loss: 1.6579e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.3376e-04 - val_loss: 1.0217e-04\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 8.5119e-05 - val_loss: 6.5989e-05\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 5.3068e-05 - val_loss: 3.9368e-05\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.2173e-05 - val_loss: 2.3723e-05\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.8984e-05 - val_loss: 1.3916e-05\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.0861e-05 - val_loss: 7.7689e-06\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 6.1669e-06 - val_loss: 4.2635e-06\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 3.2912e-06 - val_loss: 2.2761e-06\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.7406e-06 - val_loss: 1.1723e-06\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 8.8012e-07 - val_loss: 5.9230e-07\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 4.3580e-07 - val_loss: 2.9925e-07\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 171us/step - loss: 2.0404e-07 - val_loss: 1.3995e-07\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.0124e-07 - val_loss: 5.9685e-08\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 4.1903e-08 - val_loss: 2.4849e-08\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.8323e-08 - val_loss: 1.0461e-08\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 6.9560e-09 - val_loss: 4.8394e-09\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.1612e-09 - val_loss: 2.0086e-09\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.3009e-09 - val_loss: 8.3514e-10\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.9092e-10 - val_loss: 5.9007e-10\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 5.2555e-10 - val_loss: 5.0422e-10\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.0772e-10 - val_loss: 3.5432e-10\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 175us/step - loss: 3.1188e-10 - val_loss: 3.4910e-10\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.7586e-10 - val_loss: 2.8855e-10\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.5669e-10 - val_loss: 2.7704e-10\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 2.5556e-10 - val_loss: 3.1186e-10\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.6416e-10 - val_loss: 2.7789e-10\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 3.0511e-10 - val_loss: 5.9770e-10\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 2.6057e-10 - val_loss: 2.9675e-10\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.5562e-10 - val_loss: 2.8325e-10\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 3.9636e-10 - val_loss: 3.5225e-10\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 3.1407e-10 - val_loss: 3.5866e-10\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 5.1051e-10 - val_loss: 2.8648e-10\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.8561e-10 - val_loss: 2.7706e-10\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 3.0135e-10 - val_loss: 4.8341e-10\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 4.3455e-10 - val_loss: 4.4302e-10\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 3.6220e-10 - val_loss: 2.6015e-10\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 176us/step - loss: 3.7613e-10 - val_loss: 2.8729e-10\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 3.7521e-10 - val_loss: 3.8282e-10\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.1172e-10 - val_loss: 3.4267e-10\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 3.1964e-10 - val_loss: 4.4631e-10\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.5113e-10 - val_loss: 4.3575e-10\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.4104e-10 - val_loss: 3.0603e-10\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 3.9889e-10 - val_loss: 2.0084e-09\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.1996e-10 - val_loss: 4.3696e-10\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 4.9237e-10 - val_loss: 6.3224e-10\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 8.3161e-10 - val_loss: 3.9472e-10\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.9650e-10 - val_loss: 4.1271e-10\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.0851e-10 - val_loss: 3.1996e-10\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 179us/step - loss: 4.4869e-10 - val_loss: 2.9507e-10\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.3976e-10 - val_loss: 3.7878e-10\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 176us/step - loss: 7.2610e-10 - val_loss: 9.2914e-10\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.1220e-09 - val_loss: 5.3890e-10\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.1885e-09 - val_loss: 3.5830e-10\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.3277e-09 - val_loss: 5.6324e-10\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.3958e-10 - val_loss: 4.2727e-10\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 8.9672e-10 - val_loss: 4.8902e-10\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 6.6837e-10 - val_loss: 5.9023e-10\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.3363e-09 - val_loss: 3.5639e-10\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 7.4152e-10 - val_loss: 8.8021e-10\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.4822e-09 - val_loss: 2.5013e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
=======
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = layers.Input(shape=(1,), name='x')\n",
    "\n",
    "mul1, mul2, mul3 = layers.Lambda(lambda x: [x, x**2, x**3], name='lambda')(x)\n",
    "concat = layers.Concatenate(name='concat')([mul1, mul2, mul3])\n",
    "\n",
    "y = layers.Dense(1, name='y')(concat)\n",
    "\n",
    "model = models.Model(inputs=x, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 31486.7355 - val_loss: 33457.5633\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 30280.5147 - val_loss: 32201.4230\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 29085.9051 - val_loss: 30998.3500\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 27953.0183 - val_loss: 29774.5778\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 26846.3021 - val_loss: 28661.9362\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 25783.4027 - val_loss: 27571.0130\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 24752.9613 - val_loss: 26465.1635\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 23745.0452 - val_loss: 25407.5896\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 22767.7579 - val_loss: 24381.6466\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 21820.6749 - val_loss: 23385.7628\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 20905.0830 - val_loss: 22438.7728\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 20015.0460 - val_loss: 21511.3338\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 19157.1337 - val_loss: 20580.1948\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 18317.8409 - val_loss: 19719.2414\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 17517.9029 - val_loss: 18842.7163\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 16730.3456 - val_loss: 18052.9650\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 15977.9693 - val_loss: 17248.9192\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 15245.2487 - val_loss: 16472.2437\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 14536.6271 - val_loss: 15733.5110\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 13850.5076 - val_loss: 15006.3797\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 13189.7869 - val_loss: 14292.5982\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 12547.3587 - val_loss: 13611.4667\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 11927.9730 - val_loss: 12964.6604\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 11333.1632 - val_loss: 12318.8821\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 10752.8541 - val_loss: 11724.7511\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 10197.6908 - val_loss: 11129.6634\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 9663.0244 - val_loss: 10561.9374\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 9147.6022 - val_loss: 10010.5999\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 8650.0341 - val_loss: 9490.4057\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 8175.1109 - val_loss: 8970.9797\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 7714.5702 - val_loss: 8483.7950\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 7275.9299 - val_loss: 8007.1055\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 6852.3778 - val_loss: 7555.2740\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 6445.9422 - val_loss: 7126.0890\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 6058.6107 - val_loss: 6703.5591\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 5685.8938 - val_loss: 6306.7351\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5329.6032 - val_loss: 5917.9692\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 4988.0255 - val_loss: 5551.7808\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 4662.9334 - val_loss: 5201.6711\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 4353.2674 - val_loss: 4869.2680\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4058.5372 - val_loss: 4547.3700\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3777.6065 - val_loss: 4245.7391\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3511.7093 - val_loss: 3951.8892\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3257.6219 - val_loss: 3678.5366\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3018.7312 - val_loss: 3413.8219\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2791.6258 - val_loss: 3167.2442\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2577.0587 - val_loss: 2930.8024\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2374.2690 - val_loss: 2714.2460\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2185.2612 - val_loss: 2497.5101\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2004.8632 - val_loss: 2302.2123\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1837.2090 - val_loss: 2114.3155\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 1679.6822 - val_loss: 1938.9179\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1532.2388 - val_loss: 1779.3533\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1395.6720 - val_loss: 1620.5272\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1267.1967 - val_loss: 1479.4331\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 1148.7761 - val_loss: 1347.3200\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1038.5451 - val_loss: 1225.0678\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 938.0672 - val_loss: 1106.6467\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 843.9699 - val_loss: 999.4912\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 757.7913 - val_loss: 903.2576\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 679.1000 - val_loss: 813.3306\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 606.8804 - val_loss: 731.7460\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 541.1817 - val_loss: 655.4160\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 481.6589 - val_loss: 584.6751\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 427.6134 - val_loss: 521.0605\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 378.6609 - val_loss: 465.7703\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 334.9625 - val_loss: 412.4995\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 295.4111 - val_loss: 366.6150\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 260.5265 - val_loss: 323.3351\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 229.0734 - val_loss: 286.7303\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 201.5622 - val_loss: 252.5406\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 176.8024 - val_loss: 224.4076\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 155.4774 - val_loss: 196.6928\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 136.3959 - val_loss: 172.9533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 119.6951 - val_loss: 153.1032\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 105.2322 - val_loss: 134.6696\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 92.5372 - val_loss: 118.7994\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 81.6245 - val_loss: 104.4921\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 72.1107 - val_loss: 92.2036\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 63.8475 - val_loss: 81.9716\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 56.7915 - val_loss: 72.3469\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 50.6999 - val_loss: 64.0002\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 45.3674 - val_loss: 57.3950\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 40.8547 - val_loss: 51.4734\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 36.9327 - val_loss: 45.8864\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 33.5393 - val_loss: 41.3200\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 30.6134 - val_loss: 37.5966\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 28.0986 - val_loss: 33.9164\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 25.8848 - val_loss: 31.0052\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 23.9945 - val_loss: 28.3784\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 22.3691 - val_loss: 26.0457\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 20.9250 - val_loss: 24.1968\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 19.7230 - val_loss: 22.4038\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 18.6376 - val_loss: 20.9638\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 17.7274 - val_loss: 19.6218\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 16.9180 - val_loss: 18.5900\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 16.2430 - val_loss: 17.5431\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 15.6437 - val_loss: 16.7146\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 15.1336 - val_loss: 15.9854\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 14.6926 - val_loss: 15.3409\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 126us/step - loss: 14.3028 - val_loss: 14.8167\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 13.9750 - val_loss: 14.2830\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 13.6866 - val_loss: 13.8769\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 13.4340 - val_loss: 13.4979\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 13.2144 - val_loss: 13.1526\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 13.0185 - val_loss: 12.8572\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 12.8458 - val_loss: 12.6049\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 12.6820 - val_loss: 12.3954\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 12.5272 - val_loss: 12.1432\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 12.3863 - val_loss: 11.9551\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 12.2488 - val_loss: 11.7501\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 12.1196 - val_loss: 11.5767\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 11.9894 - val_loss: 11.4261\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 11.8662 - val_loss: 11.2686\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 11.7308 - val_loss: 11.1132\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 11.5989 - val_loss: 10.9535\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 11.4623 - val_loss: 10.8042\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 11.3322 - val_loss: 10.6594\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 11.1977 - val_loss: 10.5142\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 11.0558 - val_loss: 10.3759\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 10.9111 - val_loss: 10.2245\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 10.7665 - val_loss: 10.0750\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 10.6162 - val_loss: 9.9299\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 10.4593 - val_loss: 9.7785\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 10.3044 - val_loss: 9.6178\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 10.1462 - val_loss: 9.4624\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 9.9899 - val_loss: 9.3050\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 9.8215 - val_loss: 9.1442\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 9.6552 - val_loss: 8.9894\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 9.4853 - val_loss: 8.8377\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 9.3112 - val_loss: 8.6623\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 9.1395 - val_loss: 8.4770\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 8.9543 - val_loss: 8.3288\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 8.7777 - val_loss: 8.1515\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 8.5982 - val_loss: 7.9843\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 8.4113 - val_loss: 7.8028\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 8.2170 - val_loss: 7.6225\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 8.0346 - val_loss: 7.4387\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 7.8457 - val_loss: 7.2564\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 7.6507 - val_loss: 7.0813\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 7.4637 - val_loss: 6.8901\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 7.2672 - val_loss: 6.7220\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.0776 - val_loss: 6.5395\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 6.8860 - val_loss: 6.3493\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 6.6844 - val_loss: 6.1670\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 6.4885 - val_loss: 5.9715\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 6.2963 - val_loss: 5.7879\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 6.1095 - val_loss: 5.6241\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5.9076 - val_loss: 5.4397\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 5.7136 - val_loss: 5.2665\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 5.5244 - val_loss: 5.0687\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 138us/step - loss: 5.3307 - val_loss: 4.8987\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 5.1429 - val_loss: 4.7149\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 4.9545 - val_loss: 4.5408\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 4.7665 - val_loss: 4.3619\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 4.5866 - val_loss: 4.2013\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 4.4062 - val_loss: 4.0258\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 4.2302 - val_loss: 3.8704\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 4.0453 - val_loss: 3.6946\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3.8769 - val_loss: 3.5348\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 3.7048 - val_loss: 3.3794\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 121us/step - loss: 3.5354 - val_loss: 3.2178\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 3.3960 - val_loss: 3.0727\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3.2265 - val_loss: 2.9251\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 3.0606 - val_loss: 2.7815\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 2.9088 - val_loss: 2.6324\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.7589 - val_loss: 2.4941\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.6159 - val_loss: 2.3646\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.4755 - val_loss: 2.2507\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3465 - val_loss: 2.1157\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 2.2031 - val_loss: 1.9888\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.0799 - val_loss: 1.8785\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.9562 - val_loss: 1.7574\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 1.8410 - val_loss: 1.6523\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.7170 - val_loss: 1.5601\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 1.6081 - val_loss: 1.4502\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.5052 - val_loss: 1.3476\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.4036 - val_loss: 1.2576\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 1.3087 - val_loss: 1.1688\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.2141 - val_loss: 1.0852\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 1.1238 - val_loss: 1.0127\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.0402 - val_loss: 0.9352\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.9604 - val_loss: 0.8571\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 0.8846 - val_loss: 0.7847\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.8120 - val_loss: 0.7179\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 0.7440 - val_loss: 0.6589\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.6814 - val_loss: 0.5981\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 0.6198 - val_loss: 0.5477\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 0.5641 - val_loss: 0.4941\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 0.5109 - val_loss: 0.4519\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.4619 - val_loss: 0.4085\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 0.4166 - val_loss: 0.3664\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 0.3730 - val_loss: 0.3269\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 0.3345 - val_loss: 0.2947\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.2983 - val_loss: 0.2593\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 0.2661 - val_loss: 0.2302\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.2327 - val_loss: 0.2059\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 0.2059 - val_loss: 0.1776\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 0.1799 - val_loss: 0.1557\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 0.1572 - val_loss: 0.1356\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mse')\n",
    "hist = model.fit(x_train, y_train, batch_size=10, epochs=200, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
<<<<<<< HEAD
    },
=======
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "y_weights\n",
      "[array([[1.000005 ],\n",
      "       [1.9999974],\n",
      "       [3.0000005]], dtype=float32), array([0.99999946], dtype=float32)]\n"
=======
      "y_weights:\n",
      " [array([[1.3327758],\n",
      "       [1.9967649],\n",
      "       [2.9816322]], dtype=float32), array([1.0248761], dtype=float32)]\n"
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = np.random.rand(1000,1) * 10 - 5\n",
    "y_train = 1 * x_train + 2 * x_train**2 + 3 * x_train**3 + 1\n",
    "\n",
    "x = layers.Input(shape=(1,), name='x')\n",
    "h1_A, h1_B, h1_C = layers.Lambda(lambda x: [x, x**2, x**3], name='h1_ABC')(x)\n",
    "h2 = layers.Concatenate(name='concat')([h1_A, h1_B, h1_C])\n",
    "y = layers.Dense(1, name='y')(h2)\n",
    "\n",
    "model = models.Model(x, y)\n",
    "model.summary()\n",
    "\n",
    "model.compile('adam', 'mse')\n",
    "hist = model.fit(x_train, y_train, batch_size=8, epochs=200,\n",
    "                 validation_split=0.2)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "y_weights = model.get_layer('y').get_weights()\n",
    "print('y_weights'); print(y_weights)"
   ]
=======
    "y_weights = model.get_layer('y').get_weights()\n",
    "print('y_weights:\\n', y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 5c39790a2b66c52fc3aaf10f2dfe99019e0db345
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

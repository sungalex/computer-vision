{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda layer 와 Concatenate layer 를 사용하여 y = x + 2x^2 + 3x^3 + 1 관계를 피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h1_ABC (Lambda)                 [(None, 1), (None, 1 0           x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 3)            0           h1_ABC[0][0]                     \n",
      "                                                                 h1_ABC[0][1]                     \n",
      "                                                                 h1_ABC[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            4           concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 12180.1112 - val_loss: 10145.1844\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 190us/step - loss: 11226.0414 - val_loss: 9339.8587\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 10346.0991 - val_loss: 8580.7747\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 9515.4907 - val_loss: 7870.6032\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 8733.8157 - val_loss: 7223.2765\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 8012.0358 - val_loss: 6582.8464\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 7328.1766 - val_loss: 6016.5156\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 6694.1067 - val_loss: 5469.9834\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 6097.8877 - val_loss: 4981.6104\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 5546.1136 - val_loss: 4516.7881\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 196us/step - loss: 5031.2121 - val_loss: 4078.4452\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 4554.7058 - val_loss: 3675.0118\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 4111.2520 - val_loss: 3319.1925\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 3705.8462 - val_loss: 2964.6458\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 3326.9028 - val_loss: 2655.9997\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2978.7460 - val_loss: 2371.8542\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2659.3726 - val_loss: 2107.0529\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2366.4332 - val_loss: 1864.1375\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 2098.2670 - val_loss: 1644.0871\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1854.1079 - val_loss: 1445.0312\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1632.1525 - val_loss: 1266.6682\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1432.4160 - val_loss: 1103.6149\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1251.1955 - val_loss: 961.8960\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 1089.3828 - val_loss: 833.0096\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 945.4174 - val_loss: 711.8935\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 815.5768 - val_loss: 612.3938\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 701.2323 - val_loss: 525.7406\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 600.8874 - val_loss: 446.7560\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 512.3769 - val_loss: 378.5509\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 435.4041 - val_loss: 319.6348\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 368.4713 - val_loss: 270.0051\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 311.1079 - val_loss: 225.8304\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 261.6673 - val_loss: 190.1460\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 219.8416 - val_loss: 158.6424\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 184.2166 - val_loss: 132.5249\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 154.2625 - val_loss: 110.5298\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 197us/step - loss: 129.0870 - val_loss: 92.7556\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 198us/step - loss: 108.0112 - val_loss: 78.0088\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 90.4311 - val_loss: 66.0905\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 75.9319 - val_loss: 55.5347\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 63.7487 - val_loss: 47.0397\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 198us/step - loss: 53.6861 - val_loss: 40.0199\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 45.2869 - val_loss: 34.0702\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 38.2477 - val_loss: 29.1479\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 32.3727 - val_loss: 24.9107\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 27.4301 - val_loss: 21.3322\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 23.2644 - val_loss: 18.2402\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 19.7140 - val_loss: 15.6301\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 16.7039 - val_loss: 13.2963\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 14.1254 - val_loss: 11.3342\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 11.9399 - val_loss: 9.6340\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 10.0602 - val_loss: 8.1604\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 8.4695 - val_loss: 6.8984\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 7.1272 - val_loss: 5.8234\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 5.9989 - val_loss: 4.9308\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 5.0584 - val_loss: 4.1818\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 196us/step - loss: 4.2746 - val_loss: 3.5536\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.6392 - val_loss: 3.0621\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 3.1209 - val_loss: 2.6459\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.6995 - val_loss: 2.3262\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.3717 - val_loss: 2.0713\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 2.1102 - val_loss: 1.8736\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 182us/step - loss: 1.9059 - val_loss: 1.7193\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.7482 - val_loss: 1.6027\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 190us/step - loss: 1.6261 - val_loss: 1.5150\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.5311 - val_loss: 1.4444\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.4563 - val_loss: 1.3899\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.3989 - val_loss: 1.3469\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.3504 - val_loss: 1.3111\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.3116 - val_loss: 1.2793\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.2765 - val_loss: 1.2501\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 1.2456 - val_loss: 1.2240\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 1.2162 - val_loss: 1.1960\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.1873 - val_loss: 1.1704\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.1592 - val_loss: 1.1426\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.1313 - val_loss: 1.1156\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.1028 - val_loss: 1.0878\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 201us/step - loss: 1.0743 - val_loss: 1.0594\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.0452 - val_loss: 1.0297\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.0166 - val_loss: 0.9993\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.9854 - val_loss: 0.9695\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.9555 - val_loss: 0.9384\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.9251 - val_loss: 0.9070\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.8940 - val_loss: 0.8763\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.8630 - val_loss: 0.8432\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.8316 - val_loss: 0.8113\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.7991 - val_loss: 0.7792\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 174us/step - loss: 0.7663 - val_loss: 0.7484\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.7349 - val_loss: 0.7156\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.7024 - val_loss: 0.6826\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.6706 - val_loss: 0.6498\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.6389 - val_loss: 0.6180\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.6077 - val_loss: 0.5865\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.5764 - val_loss: 0.5554\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.5444 - val_loss: 0.5257\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.5150 - val_loss: 0.4959\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.4854 - val_loss: 0.4667\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.4546 - val_loss: 0.4351\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 171us/step - loss: 0.4265 - val_loss: 0.4069\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.3977 - val_loss: 0.3799\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.3707 - val_loss: 0.3532\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.3447 - val_loss: 0.3270\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.3178 - val_loss: 0.3008\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.2945 - val_loss: 0.2777\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.2703 - val_loss: 0.2542\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.2471 - val_loss: 0.2327\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.2253 - val_loss: 0.2116\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.2053 - val_loss: 0.1911\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.1859 - val_loss: 0.1726\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.1673 - val_loss: 0.1555\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.1499 - val_loss: 0.1391\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.1337 - val_loss: 0.1245\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1195 - val_loss: 0.1102\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.1054 - val_loss: 0.0966\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0924 - val_loss: 0.0845\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 173us/step - loss: 0.0812 - val_loss: 0.0737\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0703 - val_loss: 0.0638\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0606 - val_loss: 0.0559\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.0523 - val_loss: 0.0471\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0445 - val_loss: 0.0400\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0379 - val_loss: 0.0336\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0318 - val_loss: 0.0279\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0263 - val_loss: 0.0232\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0218 - val_loss: 0.0191\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0178 - val_loss: 0.0156\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 9.6120e-04 - val_loss: 7.7686e-04\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 6.7015e-04 - val_loss: 5.3414e-04\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - ETA: 0s - loss: 4.7975e-0 - 0s 177us/step - loss: 4.5957e-04 - val_loss: 3.6323e-04\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.0815e-04 - val_loss: 2.4522e-04\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 2.0695e-04 - val_loss: 1.6579e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.3376e-04 - val_loss: 1.0217e-04\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 8.5119e-05 - val_loss: 6.5989e-05\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 192us/step - loss: 5.3068e-05 - val_loss: 3.9368e-05\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.2173e-05 - val_loss: 2.3723e-05\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.8984e-05 - val_loss: 1.3916e-05\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.0861e-05 - val_loss: 7.7689e-06\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 6.1669e-06 - val_loss: 4.2635e-06\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 3.2912e-06 - val_loss: 2.2761e-06\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.7406e-06 - val_loss: 1.1723e-06\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 8.8012e-07 - val_loss: 5.9230e-07\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 4.3580e-07 - val_loss: 2.9925e-07\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 171us/step - loss: 2.0404e-07 - val_loss: 1.3995e-07\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 175us/step - loss: 1.0124e-07 - val_loss: 5.9685e-08\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 4.1903e-08 - val_loss: 2.4849e-08\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 1.8323e-08 - val_loss: 1.0461e-08\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 6.9560e-09 - val_loss: 4.8394e-09\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 3.1612e-09 - val_loss: 2.0086e-09\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 178us/step - loss: 1.3009e-09 - val_loss: 8.3514e-10\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.9092e-10 - val_loss: 5.9007e-10\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 5.2555e-10 - val_loss: 5.0422e-10\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.0772e-10 - val_loss: 3.5432e-10\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 175us/step - loss: 3.1188e-10 - val_loss: 3.4910e-10\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.7586e-10 - val_loss: 2.8855e-10\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.5669e-10 - val_loss: 2.7704e-10\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 2.5556e-10 - val_loss: 3.1186e-10\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 2.6416e-10 - val_loss: 2.7789e-10\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 3.0511e-10 - val_loss: 5.9770e-10\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 2.6057e-10 - val_loss: 2.9675e-10\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.5562e-10 - val_loss: 2.8325e-10\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 3.9636e-10 - val_loss: 3.5225e-10\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 3.1407e-10 - val_loss: 3.5866e-10\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 5.1051e-10 - val_loss: 2.8648e-10\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 2.8561e-10 - val_loss: 2.7706e-10\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 3.0135e-10 - val_loss: 4.8341e-10\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 177us/step - loss: 4.3455e-10 - val_loss: 4.4302e-10\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 3.6220e-10 - val_loss: 2.6015e-10\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 176us/step - loss: 3.7613e-10 - val_loss: 2.8729e-10\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 3.7521e-10 - val_loss: 3.8282e-10\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 4.1172e-10 - val_loss: 3.4267e-10\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 188us/step - loss: 3.1964e-10 - val_loss: 4.4631e-10\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 4.5113e-10 - val_loss: 4.3575e-10\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.4104e-10 - val_loss: 3.0603e-10\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 3.9889e-10 - val_loss: 2.0084e-09\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 5.1996e-10 - val_loss: 4.3696e-10\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 4.9237e-10 - val_loss: 6.3224e-10\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 186us/step - loss: 8.3161e-10 - val_loss: 3.9472e-10\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 4.9650e-10 - val_loss: 4.1271e-10\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.0851e-10 - val_loss: 3.1996e-10\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 179us/step - loss: 4.4869e-10 - val_loss: 2.9507e-10\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.3976e-10 - val_loss: 3.7878e-10\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 176us/step - loss: 7.2610e-10 - val_loss: 9.2914e-10\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 183us/step - loss: 1.1220e-09 - val_loss: 5.3890e-10\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 182us/step - loss: 1.1885e-09 - val_loss: 3.5830e-10\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 180us/step - loss: 2.3277e-09 - val_loss: 5.6324e-10\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 187us/step - loss: 7.3958e-10 - val_loss: 4.2727e-10\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 189us/step - loss: 8.9672e-10 - val_loss: 4.8902e-10\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 6.6837e-10 - val_loss: 5.9023e-10\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 185us/step - loss: 1.3363e-09 - val_loss: 3.5639e-10\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 7.4152e-10 - val_loss: 8.8021e-10\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 181us/step - loss: 1.4822e-09 - val_loss: 2.5013e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_weights\n",
      "[array([[1.000005 ],\n",
      "       [1.9999974],\n",
      "       [3.0000005]], dtype=float32), array([0.99999946], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = np.random.rand(1000,1) * 10 - 5\n",
    "y_train = 1 * x_train + 2 * x_train**2 + 3 * x_train**3 + 1\n",
    "\n",
    "x = layers.Input(shape=(1,), name='x')\n",
    "h1_A, h1_B, h1_C = layers.Lambda(lambda x: [x, x**2, x**3], name='h1_ABC')(x)\n",
    "h2 = layers.Concatenate(name='concat')([h1_A, h1_B, h1_C])\n",
    "y = layers.Dense(1, name='y')(h2)\n",
    "\n",
    "model = models.Model(x, y)\n",
    "model.summary()\n",
    "\n",
    "model.compile('adam', 'mse')\n",
    "hist = model.fit(x_train, y_train, batch_size=8, epochs=200,\n",
    "                 validation_split=0.2)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "y_weights = model.get_layer('y').get_weights()\n",
    "print('y_weights'); print(y_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
